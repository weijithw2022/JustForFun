{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1872300,"sourceType":"datasetVersion","datasetId":1114664},{"sourceId":1187,"sourceType":"datasetVersion","datasetId":626}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:10:00.328716Z","iopub.execute_input":"2025-05-17T10:10:00.328993Z","iopub.status.idle":"2025-05-17T10:10:00.722754Z","shell.execute_reply.started":"2025-05-17T10:10:00.328974Z","shell.execute_reply":"2025-05-17T10:10:00.721950Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/movielens-1m-dataset/users.dat\n/kaggle/input/movielens-1m-dataset/ratings.dat\n/kaggle/input/movielens-1m-dataset/README\n/kaggle/input/movielens-1m-dataset/movies.dat\n/kaggle/input/movielens-100k-dataset/ml-100k/u.occupation\n/kaggle/input/movielens-100k-dataset/ml-100k/u1.base\n/kaggle/input/movielens-100k-dataset/ml-100k/u.info\n/kaggle/input/movielens-100k-dataset/ml-100k/u4.test\n/kaggle/input/movielens-100k-dataset/ml-100k/u.item\n/kaggle/input/movielens-100k-dataset/ml-100k/README\n/kaggle/input/movielens-100k-dataset/ml-100k/u1.test\n/kaggle/input/movielens-100k-dataset/ml-100k/ua.test\n/kaggle/input/movielens-100k-dataset/ml-100k/u.data\n/kaggle/input/movielens-100k-dataset/ml-100k/u5.test\n/kaggle/input/movielens-100k-dataset/ml-100k/mku.sh\n/kaggle/input/movielens-100k-dataset/ml-100k/u5.base\n/kaggle/input/movielens-100k-dataset/ml-100k/u.user\n/kaggle/input/movielens-100k-dataset/ml-100k/ub.base\n/kaggle/input/movielens-100k-dataset/ml-100k/u4.base\n/kaggle/input/movielens-100k-dataset/ml-100k/u2.test\n/kaggle/input/movielens-100k-dataset/ml-100k/ua.base\n/kaggle/input/movielens-100k-dataset/ml-100k/u3.test\n/kaggle/input/movielens-100k-dataset/ml-100k/u.genre\n/kaggle/input/movielens-100k-dataset/ml-100k/allbut.pl\n/kaggle/input/movielens-100k-dataset/ml-100k/u3.base\n/kaggle/input/movielens-100k-dataset/ml-100k/u2.base\n/kaggle/input/movielens-100k-dataset/ml-100k/ub.test\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable\n\nmovies = pd.read_csv('/kaggle/input/movielens-1m-dataset/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\nratings = pd.read_csv('/kaggle/input/movielens-1m-dataset/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\nusers = pd.read_csv('/kaggle/input/movielens-1m-dataset/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\ntraining_set = pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u1.base', delimiter = '\\t')\ntraining_set = np.array(training_set, dtype = 'int')\ntesting_set = pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u1.test', delimiter = '\\t')\ntesting_set = np.array(testing_set, dtype = 'int')\nno_users = int(max(max(training_set[:,0]), max(testing_set[:,0])))\nno_movies = int(max(max(training_set[:,1]), max(testing_set[:,1])))\n\ndef convert_data(data):\n    new_data = []\n    for id_users in range(1, no_users + 1):\n        id_movies = data[:,1][data[:,0] == id_users]\n        id_ratings = data[:,2][data[:,0] == id_users]\n        ratings = np.zeros(no_movies)\n        ratings[id_movies - 1] = id_ratings\n        new_data.append(list(ratings))\n    return new_data\n\ntraining_set = convert_data(training_set)\ntesting_set = convert_data(testing_set)\n\ntraining_set = torch.FloatTensor(training_set)\ntesting_set = torch.FloatTensor(testing_set)\n\ntraining_set[training_set == 0] = -1\ntraining_set[training_set == 1] = 0\ntraining_set[training_set == 2] = 0\ntraining_set[training_set >= 3] = 1\ntesting_set[testing_set == 0] = -1\ntesting_set[testing_set == 1] = 0\ntesting_set[testing_set == 2] = 0\ntesting_set[testing_set >= 3] = 1\n\nclass RBM:\n    def __init__(self, nv, nh):\n        self.W = torch.randn(nh,nv)\n        self.b = torch.randn(1, nv)\n        self.a = torch.randn(1, nh)\n        \n    def sample_h(self, v):\n        vw = torch.mm(v, self.W.T)\n        activation = vw + self.a.expand_as(vw)\n        p_h_given_v = torch.sigmoid(activation)\n        return p_h_given_v, torch.bernoulli(p_h_given_v)\n\n    def sample_v(self, h):\n        hw = torch.mm(h, self.W)\n        activation = hw + self.b.expand_as(hw)\n        p_v_given_h = torch.sigmoid(activation)\n        return p_v_given_h, torch.bernoulli(p_v_given_h)\n\n    def train(self, v0, vk, p_h0_given_v0, p_hk_given_vk):\n        # Gibbs Sampling\n        self.W += (torch.mm(v0.T, p_h0_given_v0)-torch.mm(vk.T, p_hk_given_vk)).T\n        self.b += torch.sum((v0-vk), 0)\n        self.a += torch.sum((p_h0_given_v0-p_hk_given_vk), 0)\n\nnv = len(training_set[0])\nnh = 100\nbatch_size = 100\nrbm = RBM(nv, nh)\n\nno_epochs = 10\n\nfor epoch in range(1, no_epochs + 1):\n    train_loss = 0\n    s = 0.\n    for id_user in range(0, no_users-batch_size, batch_size):\n        v0 = training_set[id_user:id_user+batch_size]\n        vk = v0.clone()    \n        p_h0_given_v0,_ = rbm.sample_h(v0)\n        for k in range(10):\n            _, hk = rbm.sample_h(vk)\n            _, vk = rbm.sample_v(hk)\n            vk[v0<0] = v0[v0<0]\n        p_hk_given_vk,_ = rbm.sample_h(vk)\n        rbm.train(v0, vk, p_h0_given_v0, p_hk_given_vk)\n        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n        s += 1.\n    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n\ntest_loss = 0\ns = 0.\n\nfor id_user in range(no_users):\n    v = training_set[id_user:id_user+1]\n    vt = testing_set[id_user:id_user+1]\n    if len(vt[vt>=0]) > 0:\n        _,h = rbm.sample_h(v)\n        _,v = rbm.sample_v(h)\n        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n        s += 1.\nprint('test loss: '+str(test_loss/s))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:05:19.140525Z","iopub.execute_input":"2025-05-17T11:05:19.140927Z","iopub.status.idle":"2025-05-17T11:05:31.752634Z","shell.execute_reply.started":"2025-05-17T11:05:19.140899Z","shell.execute_reply":"2025-05-17T11:05:31.751761Z"}},"outputs":[{"name":"stdout","text":"epoch: 1 loss: tensor(0.3588)\nepoch: 2 loss: tensor(0.2525)\nepoch: 3 loss: tensor(0.2465)\nepoch: 4 loss: tensor(0.2537)\nepoch: 5 loss: tensor(0.2448)\nepoch: 6 loss: tensor(0.2381)\nepoch: 7 loss: tensor(0.2431)\nepoch: 8 loss: tensor(0.2470)\nepoch: 9 loss: tensor(0.2489)\nepoch: 10 loss: tensor(0.2454)\ntest loss: tensor(0.2353)\n","output_type":"stream"}],"execution_count":4}]}